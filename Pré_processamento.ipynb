{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CfJjvur6Ec03h-8jLjFu9Q3LUKnAuYRt",
      "authorship_tag": "ABX9TyOuxOaCm5y7nGVLSY4iOTHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenryLimaa/JPasEDR-Gaia/blob/master/Pr%C3%A9_processamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1klSt7qV9u-"
      },
      "source": [
        "## 1. Importação das Bibliotecas\n",
        "\n",
        "O ponto de partida de qualquer análise em Python é a importação das bibliotecas. O código carrega o \"canivete suíço\" da ciência de dados: pandas para a manipulação de tabelas (DataFrames) , numpy para operações numéricas eficientes , matplotlib e seaborn para a visualização gráfica, e sklearn para ferramentas de aprendizado de máquina."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulação de Sistema e Arquivos\n",
        "import os\n",
        "import threading\n",
        "import random\n",
        "\n",
        "# Processamento de Dados e Matemática\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualização de Dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "# Machine Learning e Estatística\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "rZFK7RyOurPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVX6DIbIWNIR"
      },
      "source": [
        "## 2. Leitura do Arquivo CSV\n",
        "\n",
        "Imediatamente após a importação das bibliotecas, ocorre a leitura do arquivo CSV. O comando pd.read_csv  carrega os dados brutos para a memória, armazenando-os na variável df. A contagem de linhas (len(df)) revela a escala do problema: um conjunto de 17.378 estrelas, informação crucial para o planejamento computacional.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvIY9kbbWPeO"
      },
      "outputs": [],
      "source": [
        "# Carregamos oS arquivoS CSV em DataFrames do Pandas de forma individualizada.\n",
        "\n",
        "# MAGNITUDE\n",
        "df = pd.read_csv('/content/drive/MyDrive/Notebook fotometrias/Conjunto de dados(crossmating JPASEDR-GAIA).csv')\n",
        "df_err = pd.read_csv('/content/drive/MyDrive/Notebook fotometrias/ERR_Conjunto de dados(crossmating JPASEDR-GAIA).csv')\n",
        "\n",
        "# FLUXO\n",
        "df_flux = pd.read_csv('/content/drive/MyDrive/Notebook fotometrias/FLUX_APER_COR_3_0.csv')\n",
        "df_err_flux = pd.read_csv('/content/drive/MyDrive/Notebook fotometrias/FLUX_RELERR_APER_COR_3_0.csv')\n",
        "\n",
        "\n",
        "# Contar o número de linhas (excluindo o cabeçalho)\n",
        "numero_estrelas = len(df)\n",
        "numero_estrelas_err = len(df_err)\n",
        "numero_estrelas_flux = len(df_flux)\n",
        "numero_estrelas_err_flux = len(df_err_flux)\n",
        "\n",
        "\n",
        "print(f\"O número total de estrelas (MAGNITUDE) é: {numero_estrelas}\")\n",
        "print(f\"O número total de estrelas (ERRO MAGNITUDE) é: {numero_estrelas_err}\")\n",
        "print(f\"O número total de estrelas (FLUXO) é: {numero_estrelas_flux}\")\n",
        "print(f\"O número total de estrelas (ERRO FLUXO) é: {numero_estrelas_err_flux}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8Xik13WjJj"
      },
      "source": [
        "## 3. Visualização dos Dados\n",
        "\n",
        "#### Exibição das Primeiras Linhas do DataFrame\n",
        "\n",
        "O objetivo deste item é exibir as primeiras linhas do DataFrame para entender sua estrutura. O DataFrame contém colunas como `TILE_ID`, `NUMBER`, `MAG_APER_COR_3_0`, `Pk`, `e_Pk` e `erro_relativo_paralaxe`. A coluna `MAG_APER_COR_3_0` contém múltiplos valores de fotometria em diferentes bandas/momentos. Já o dataframe que possui `TILE_ID`, `NUMBER`, `MAG_ERR_APER_COR_3_0`, `Pk`, `e_Pk` e `erro_relativo_paralaxe` é relacionado ao Vetor de erro para magnitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmR3dESaWqcX"
      },
      "outputs": [],
      "source": [
        "#Exibimos as primeiras linhas do DataFrame para entender sua estrutura.\n",
        "print(\"Primeiras linhas do DataFrame:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de modificar qualquer dado, é vital inspecioná-lo. Inicialmente realiza-se a visualização das primeiras linhas com df.head(). Esta é uma etapa diagnóstica essencial. A saída revela imediatamente o primeiro desafio de pré-processamento: as colunas MAG_APER_COR_3_0 e MAG_ERR_APER_COR_3_0 não são um valor único, mas sim uma string de texto contendo dezenas de valores de magnitude separados por espaços, o primeirosão os valores propriamente dito das agnitudes e o segundo é o erro por cada uma delas."
      ],
      "metadata": {
        "id": "T16Tok9WFoM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas do DataFrame dos erros para entender sua estrutura.\n",
        "print(\"Primeiras linhas do DataFrame:\")\n",
        "df_err.head()"
      ],
      "metadata": {
        "id": "mCHHpbBagVPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas do DataFrame (FLUXO) para entender sua estrutura.\n",
        "print(\"Primeiras linhas do DataFrame:\")\n",
        "df_flux.head()"
      ],
      "metadata": {
        "id": "-gbq1bSW1N6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas do DataFrame (ERROS FLUXO) para entender sua estrutura.\n",
        "print(\"Primeiras linhas do DataFrame:\")\n",
        "df_err_flux.head()"
      ],
      "metadata": {
        "id": "Y7ptOWv81OME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-H2OJKWWs-t"
      },
      "source": [
        "## 4. Pré-processamento dos Dados\n",
        "\n",
        "Neste item, a coluna `MAG_APER_COR_3_0` é dividida em 57 colunas separadas, cada uma contendo um valor de fotometria. Isso é feito usando o método `str.split(expand=True)`, que divide a string em múltiplas colunas com base nos espaços. Após a divisão, os valores são convertidos para numéricos usando `pd.to_numeric`.\n",
        "\n",
        "O DataFrame resultante tem 63 colunas, incluindo as novas colunas de fotometria (`Fotometria_1`, `Fotometria_2`, etc.). Esse pré-processamento é crucial para análises posteriores, pois permite que cada valor de fotometria seja tratado individualmente."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. PROCESSAMENTO SEPARADO PARA CADA DATAFRAME\n",
        "\n",
        "# Para df (magnitude)\n",
        "colunas_fotometria = [f'Fotometria_{i+1}' for i in range(57)]\n",
        "\n",
        "# Para df_err (erros magnitude)\n",
        "colunas_err_fotometria = [f'Fotometria_{i+1}' for i in range(57)]\n",
        "\n",
        "# Para df_flux (fluxo)\n",
        "colunas_flux_fotometria = [f'Fotometria_{i+1}' for i in range(57)]\n",
        "\n",
        "# Para df_err_flux (erros fluxo relativo)\n",
        "colunas_err_flux_fotometria = [f'Fotometria_{i+1}' for i in range(57)]"
      ],
      "metadata": {
        "id": "J0I-nBeArDTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as colunas do DataFrame\n",
        "print(\"Colunas do DataFrame:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "PmIF8M8drM8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as colunas do DataFrame\n",
        "print(\"Colunas do DataFrame:\")\n",
        "print(df_err.columns)"
      ],
      "metadata": {
        "id": "ShXsF_tgrYKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as colunas do DataFrame\n",
        "print(\"Colunas do DataFrame:\")\n",
        "print(df_flux.columns)"
      ],
      "metadata": {
        "id": "KzG9fQYD1_aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as colunas do DataFrame\n",
        "print(\"Colunas do DataFrame:\")\n",
        "print(df_err_flux.columns)"
      ],
      "metadata": {
        "id": "ez23UMzn1_o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos as colunas `MAG_APER_COR_3_0`, 'MAG_ERR_APER_COR_3_0' 'FLUX_APER_COR_3_0' e 'FLUX_RELERR_APER_COR_3_0'  em 57 colunas.\n",
        "df[colunas_fotometria] = df['MAG_APER_COR_3_0'].str.split(expand=True)\n",
        "df_err[colunas_err_fotometria] = df_err['MAG_ERR_APER_COR_3_0'].str.split(expand=True)\n",
        "df_flux[colunas_flux_fotometria] = df_flux['FLUX_APER_COR_3_0'].str.split(expand=True)\n",
        "df_err_flux[colunas_err_flux_fotometria] = df_err_flux['FLUX_RELERR_APER_COR_3_0'].str.split(expand=True)\n"
      ],
      "metadata": {
        "id": "DDf6VIFmrxDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertemos os valores para numéricos.\n",
        "df[colunas_fotometria] = df[colunas_fotometria].apply(pd.to_numeric)\n",
        "df_err[colunas_err_fotometria] = df_err[colunas_err_fotometria].apply(pd.to_numeric)\n",
        "df_flux[colunas_flux_fotometria] = df_flux[colunas_flux_fotometria].apply(pd.to_numeric)\n",
        "df_err_flux[colunas_err_flux_fotometria] = df_err_flux[colunas_err_flux_fotometria].apply(pd.to_numeric)"
      ],
      "metadata": {
        "id": "Z6J_iN_-sIUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas após o pré-processamento.\n",
        "\n",
        "print(\"\\nDataFrame após divisão da coluna de fotometria:\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-eXtGihbsakd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas após o pré-processamento.\n",
        "\n",
        "print(\"\\nDataFrame após divisão da coluna de erro fotometria:\")\n",
        "df_err.head()"
      ],
      "metadata": {
        "id": "vZ72ytHrsasT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas após o pré-processamento.\n",
        "\n",
        "print(\"\\nDataFrame após divisão da coluna de fluxo:\")\n",
        "df_flux.head()"
      ],
      "metadata": {
        "id": "SV-GcMd-6520",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exibimos as primeiras linhas após o pré-processamento.\n",
        "\n",
        "print(\"\\nDataFrame após divisão da coluna de erro_fluxo:\")\n",
        "df_err_flux.head()"
      ],
      "metadata": {
        "id": "c21MVGjO66DU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. RENOMEÇÃO PARA AMBOS OS DATAFRAMES (Renomear as bandas fotométricas)\n",
        "\n",
        "# Carregar o arquivo CSV com os nomes das bandas\n",
        "df_filters = pd.read_csv('/content/drive/MyDrive/Notebook fotometrias/filters_names.csv')\n",
        "\n",
        "# Extrair os nomes das bandas fotométricas\n",
        "filter_names = df_filters['name'].tolist()\n",
        "\n",
        "# Verificar se temos 57 nomes de banda (para corresponder às 57 colunas de fotometria)\n",
        "if len(filter_names) == 57:\n",
        "    # Criar um dicionário para mapear os nomes antigos para os novos\n",
        "    rename_dict = {f'Fotometria_{i+1}': filter_names[i] for i in range(57)}\n",
        "\n",
        "    # Renomear as colunas no DataFrame principal\n",
        "    df = df.rename(columns=rename_dict)\n",
        "    df_err = df_err.rename(columns=rename_dict)\n",
        "    df_flux = df_flux.rename(columns=rename_dict)\n",
        "    df_err_flux = df_err_flux.rename(columns=rename_dict)\n",
        "\n",
        "    print(\"Bandas fotométricas renomeadas com sucesso!\")\n",
        "else:\n",
        "    print(f\"Atenção: Número de bandas ({len(filter_names)}) não corresponde ao número de colunas de fotometria (57)\")"
      ],
      "metadata": {
        "id": "J9Z74raav5_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YEicS78W5O6"
      },
      "outputs": [],
      "source": [
        "# 3. REMOVER COLUNAS ORIGINAIS\n",
        "df = df.drop(['MAG_APER_COR_3_0'], axis=1)\n",
        "df_err = df_err.drop(['MAG_ERR_APER_COR_3_0'], axis=1)\n",
        "df_flux = df_flux.drop(['FLUX_APER_COR_3_0'], axis=1)\n",
        "df_err_flux = df_err_flux.drop(['FLUX_RELERR_APER_COR_3_0'], axis=1)\n",
        "\n",
        "print(\"Colunas originais removidas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as primeiras linhas após o pré-processamento\n",
        "print(\"\\nDataFrame após divisão e renomeação das colunas de fotometria:\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2ztBBT4byr3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as primeiras linhas após o pré-processamento\n",
        "print(\"\\nDataFrame após divisão e renomeação das colunas de fotometria:\")\n",
        "df_err.head()"
      ],
      "metadata": {
        "id": "epV3r3m5y-eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as primeiras linhas após o pré-processamento\n",
        "print(\"\\nDataFrame após divisão e renomeação das colunas de fotometria:\")\n",
        "df_flux.head()"
      ],
      "metadata": {
        "id": "OVhEYUpw8WDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir as primeiras linhas após o pré-processamento\n",
        "print(\"\\nDataFrame após divisão e renomeação das colunas de fotometria:\")\n",
        "df_err_flux.head()"
      ],
      "metadata": {
        "id": "PRX4ydcO8WOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esses blocos executam o \"coração\" do pré-processamento. O objetivo é \"desmembrar\" aquela string problemática em colunas numéricas individuais.\n",
        "\n",
        "Primeiro, uma lista de 57 nomes de colunas genéricos (ex: Fotometria_1, Fotometria_2...) é criada.\n",
        "\n",
        "Em seguida, o método str.split(expand=True) é aplicado à coluna MAG_APER_COR_3_0. Esta função \"fatia\" a string em cada espaço, e o expand=True garante que cada valor fatiado se torne uma nova coluna no DataFrame.\n",
        "\n",
        "Finalmente, o método apply(pd.to_numeric) é usado para converter essas novas colunas, que ainda são texto, em valores numéricos. Sem essa conversão, nenhum cálculo matemático seria possível.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Com os dados estruturalmente corretos, o foco muda para o \"enriquecimento semântico\". Com a substituição dos nomes genéricos (ex:Fotometria_1, Fotometria_2, Fotometria_3, etc) pelos nomes científicos reais das bandas fotométricas (ex: uJAVA, J0378, etc.). Isso é feito carregando-se um segundo arquivo CSV (804024.csv) que contém o mapeamento de nomes e aplicando o método df.rename. Esta etapa, embora simples, é crucial para a interpretabilidade científica dos resultados. A seguir, o notebook entra na FASE 1: Verificação de valores nulos\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7ZSbUfKGyUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **GERANDO ARQUIVOS DOS DATAFRAMES APÓS RENOMEÇÃO**"
      ],
      "metadata": {
        "id": "b5cbl69xPlxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"GERANDO ARQUIVOS DOS DATAFRAMES APÓS RENOMEÇÃO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Salvar os dataframes processados para uso futuro\n",
        "df.to_csv('/content/drive/MyDrive/Notebook fotometrias/df_magnitudes_processado.csv', index=False)\n",
        "df_err.to_csv('/content/drive/MyDrive/Notebook fotometrias/df_erros_processado.csv', index=False)\n",
        "df_flux.to_csv('/content/drive/MyDrive/Notebook fotometrias/df_fluxo_processado.csv', index=False)\n",
        "df_err_flux.to_csv('/content/drive/MyDrive/Notebook fotometrias/df_erro_fluxo_processado.csv', index=False)\n",
        "\n",
        "print(\"DataFrames salvos com sucesso!\")\n",
        "print(f\"df shape: {df.shape}\")\n",
        "print(f\"df_err shape: {df_err.shape}\")\n",
        "print(f\"df_flux shape: {df_flux.shape}\")\n",
        "print(f\"df_err_flux shape: {df_err_flux.shape}\")\n",
        "print(f\"Bandas disponíveis: {len(filter_names)}\")\n",
        "print(\"\\nPrimeiras 10 bandas:\", filter_names[:10])"
      ],
      "metadata": {
        "id": "mloIanX1PlK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.1 Verificar valores nulos, NA, NaN em todas as bandas**\n",
        "\n",
        "Em astronomia, dados ausentes podem ser representados por valores padrão (NaN, None) ou por placeholders (valores sentinela), como 99. O código, de forma prudente, verifica ambos:\n",
        "\n",
        "\n",
        "\n",
        "1.   Na procura por NaN ou None. A saída mostra 0 para todas as bandas .\n",
        "2.   Um laço for verifica explicitamente a contagem de valores == 99. A saída também retorna 0 para todas as bandas.\n",
        "\n",
        "A vantagem desta verificação dupla é a robustez. A desvantagem de não encontrar valores nulos é estatisticamente improvável em dados reais, o que pode sugerir que um filtro de limpeza já foi aplicado na origem dos dados, ou que o valor 99 foi apenas um exemplo e outros placeholders (como -99 ou 99.99) poderiam existir.\n",
        "\n"
      ],
      "metadata": {
        "id": "m5d1NRa2QQZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VERIFICAÇÃO DE VALORES NULOS E AUSENTES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Lista de valores sentinela comuns em dados astronômicos\n",
        "valores_sentinela = [99, -99, 99.99, -99.99, 999, -999, 999.999, -999.999, 0, -1]\n",
        "\n",
        "def verificar_dados_ausentes(df, df_err, df_flux, df_err_flux, filter_names, valores_sentinela):\n",
        "    \"\"\"\n",
        "    Função melhorada para verificação de dados ausentes e valores sentinela\n",
        "    IMPORTANTE: Não remove outliers pois eles são o foco do estudo\n",
        "    \"\"\"\n",
        "    resultados = {}\n",
        "\n",
        "    print(\"\\n 1. VERIFICAÇÃO DE VALORES AUSENTES PADRÃO:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Verificar valores nulos/ausentes padrão\n",
        "    nulos_df = df[filter_names].isnull().sum()\n",
        "    nulos_df_err = df_err[filter_names].isnull().sum()\n",
        "    nulos_df_flux = df_flux[filter_names].isnull().sum()\n",
        "    nulos_df_err_flux = df_err_flux[filter_names].isnull().sum()\n",
        "\n",
        "    print(\"Valores NaN em df (magnitudes):\")\n",
        "    print(nulos_df)\n",
        "    print(f\"\\n Total de valores NaN em df: {nulos_df.sum()}\")\n",
        "\n",
        "    print(\"\\nValores NaN em df_err (erros):\")\n",
        "    print(nulos_df_err)\n",
        "    print(f\"Total de valores NaN em df_err: {nulos_df_err.sum()}\")\n",
        "\n",
        "    print(\"Valores NaN em df_flux (fluxos):\")\n",
        "    print(nulos_df_flux)\n",
        "    print(f\"\\n Total de valores NaN em df_flux: {nulos_df_flux.sum()}\")\n",
        "\n",
        "    print(\"\\nValores NaN em df_err_flux (erros-fluxo):\")\n",
        "    print(nulos_df_err_flux)\n",
        "    print(f\"Total de valores NaN em df_err_flux: {nulos_df_err_flux.sum()}\")\n",
        "\n",
        "    # Verificar infinitos\n",
        "    infinitos_df = np.isinf(df[filter_names]).sum().sum()\n",
        "    infinitos_df_err = np.isinf(df_err[filter_names]).sum().sum()\n",
        "    infinitos_df_flux = np.isinf(df_flux[filter_names]).sum().sum()\n",
        "    infinitos_df_err_flux = np.isinf(df_err_flux[filter_names]).sum().sum()\n",
        "    print(f\"\\n Valores infinitos em df: {infinitos_df}\")\n",
        "    print(f\" Valores infinitos em df_err: {infinitos_df_err}\")\n",
        "    print(f\"\\n Valores infinitos em df_flux: {infinitos_df_flux}\")\n",
        "    print(f\" Valores infinitos em df_err_flux: {infinitos_df_err_flux}\")\n",
        "\n",
        "    print(\"\\n 2. VERIFICAÇÃO DE VALORES SENTINELA:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Verificar valores sentinela em ambas as bases\n",
        "    sentinela_encontrado = False\n",
        "    for sentinela in valores_sentinela:\n",
        "        count_sentinela_df = (df[filter_names] == sentinela).sum().sum()\n",
        "        count_sentinela_df_err = (df_err[filter_names] == sentinela).sum().sum()\n",
        "        count_sentinela_df_flux = (df_flux[filter_names] == sentinela).sum().sum()\n",
        "        count_sentinela_df_err_flux = (df_err_flux[filter_names] == sentinela).sum().sum()\n",
        "\n",
        "        if count_sentinela_df > 0 or count_sentinela_df_err > 0:\n",
        "            sentinela_encontrado = True\n",
        "            print(f\" Valor sentinela {sentinela}:\")\n",
        "            print(f\"   - df: {count_sentinela_df} ocorrências\")\n",
        "            print(f\"   - df_err: {count_sentinela_df_err} ocorrências\")\n",
        "            print(f\"   - df_flux: {count_sentinela_df_flux} ocorrências\")\n",
        "            print(f\"   - df_err_flux: {count_sentinela_df_err_flux} ocorrências\")\n",
        "\n",
        "    if not sentinela_encontrado:\n",
        "        print(\"Nenhum valor sentinela encontrado\")\n",
        "\n",
        "    print(\"\\n 3. VERIFICAÇÃO DE FAIXAS DE VALORES:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Verificar faixas de valores esperadas para magnitudes astronômicas\n",
        "    # NOTA: Não removemos outliers, apenas verificamos para diagnóstico\n",
        "    magnitudes_fora_faixa = ((df[filter_names] < 10) | (df[filter_names] > 30)).sum().sum()\n",
        "    erros_fora_faixa = ((df_err[filter_names] < 0) | (df_err[filter_names] > 5)).sum().sum()\n",
        "\n",
        "    print(f\"Magnitudes fora da faixa típica 10-30: {magnitudes_fora_faixa}\")\n",
        "    print(f\"Erros fora da faixa típica 0-5: {erros_fora_faixa}\")\n",
        "\n",
        "    # Estatísticas básicas das magnitudes\n",
        "    print(f\"\\n Estatísticas das magnitudes (todas as bandas):\")\n",
        "    print(f\"   Mínimo: {df[filter_names].min().min():.2f}\")\n",
        "    print(f\"   Máximo: {df[filter_names].max().max():.2f}\")\n",
        "    print(f\"   Média: {df[filter_names].mean().mean():.2f}\")\n",
        "\n",
        "    return {\n",
        "        'nulos_df': nulos_df,\n",
        "        'nulos_df_err': nulos_df_err,\n",
        "        'nulos_df_flux': nulos_df_flux,\n",
        "        'nulos_df_err_flux': nulos_df_err_flux,\n",
        "        'infinitos_df': infinitos_df,\n",
        "        'infinitos_df_err': infinitos_df_err,\n",
        "        'infinitos_df_flux': infinitos_df_flux,\n",
        "        'infinitos_df_err_flux': infinitos_df_err_flux,\n",
        "        'sentinela_encontrado': sentinela_encontrado,\n",
        "        }\n",
        "\n",
        "# Executar verificação melhorada\n",
        "resultados_verificacao = verificar_dados_ausentes(df, df_err, df_flux, df_err_flux, filter_names, valores_sentinela)\n",
        "\n",
        "print(\"\\n Verificação de dados concluída!\")"
      ],
      "metadata": {
        "id": "wEWQZZ9BQQ26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3 Calcular SNR (Signal-to-Noise Ratio) para cada banda**\n",
        "\n",
        "Esta seção é o objetivo final do pré-processamento: avaliar a qualidade dos dados.\n",
        "\n",
        "FASE 2: Geração do Indicador. O código calcula a Relação Sinal-Ruído (SNR). O SNR é a métrica fundamental da qualidade de uma medição; valores altos indicam um sinal limpo, valores baixos indicam um sinal ruidoso."
      ],
      "metadata": {
        "id": "D2wdmLkkRMJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Estrutura Geral**\n",
        "\n",
        "O código calcula o Signal-to-Noise Ratio (SNR) para cada estrela em cada filtro fotométrico (57 bandas), partindo dos erros relativos do fluxo.\n",
        "\n",
        "* Carrega um DataFrame pré-processado onde cada coluna (ex: 'uJAVA', 'J0378') contém valores numéricos dos erros relativos do fluxo.\n",
        "* Carrega os nomes das 57 bandas fotométricas de um arquivo CSV externo.\n",
        "* Cria uma lista filter_names contendo esses nomes.\n",
        "* Cria um novo DataFrame contendo apenas as colunas com erros relativos do fluxo para cada banda.\n",
        "* Cria nomes de colunas prefixados com 'SNR_' (ex: 'SNR_uJAVA')\n",
        "* Constrói um novo DataFrame organizado com os valores de SNR\n",
        "* Adiciona identificadores únicos e informações astrométricas para manter a rastreabilidade\n",
        "* Calcula a Média do SNR e Maior valor de SNR em todas as 57 bandas para cada estrela\n",
        "* Gera um histograma da distribuição do SNR médio\n",
        "* Salva os resultados em um novo arquivo CSV\n",
        "\n",
        "**Lógica implementada:**\n",
        "\n",
        "Para cada célula no DataFrame de erros:\n",
        "- Se erro > 0: SNR = 1 / erro_relativo\n",
        "- Se erro = 0: SNR = 0 (evita divisão por zero)"
      ],
      "metadata": {
        "id": "SmE0QEt4BCqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carregamento dos Dados\n",
        "path_dir = '/content/drive/MyDrive/Notebook fotometrias/'\n",
        "\n",
        "# Recarregar df_err_flux a partir do CSV processado.\n",
        "# Este DataFrame terá colunas como 'uJAVA', 'J0378', etc., que já são numéricas.\n",
        "df_err_flux = pd.read_csv(os.path.join(path_dir, 'df_erro_fluxo_processado.csv'))\n",
        "\n",
        "print(f\"Total de objetos carregados: {len(df_err_flux)}\")\n",
        "\n",
        "# --- INÍCIO DA IMPLEMENTAÇÃO DO SNR ---\n",
        "\n",
        "# 2. Identificar as colunas que contêm os valores de erro do fluxo\n",
        "# Precisamos obter os nomes dos filtros, que estão armazenados na variável 'filter_names' da execução anterior.\n",
        "# Para garantir a robustez, recarregaremos df_filters para assegurar que filter_names esteja preenchido corretamente.\n",
        "df_filters = pd.read_csv(os.path.join(path_dir, 'filters_names.csv'))\n",
        "filter_names = df_filters['name'].tolist()\n",
        "\n",
        "print(\"Convertendo erros relativos e calculando SNR...\")\n",
        "\n",
        "# A função get_snr_matrix não é adequada porque 'FLUX_RELERR_APER_COR_3_0' não existe mais em df_err_flux,\n",
        "# e os valores de erro já estão divididos em colunas numéricas individuais.\n",
        "\n",
        "# Seleciona apenas as colunas de filtro de df_err_flux para o cálculo da relação sinal-ruído (SNR)\n",
        "error_columns_df = df_err_flux[filter_names]\n",
        "\n",
        "# Calcular SNR para cada elemento no DataFrame error_columns_df\n",
        "# SNR = 1 / Erro_Relativo\n",
        "# np.where evita a divisão por zero quando o erro é 0.0\n",
        "with np.errstate(divide='ignore', invalid='ignore'):\n",
        "    snr_calculated_values = error_columns_df.apply(lambda x: np.where(x > 0, 1.0 / x, 0.0))\n",
        "\n",
        "# 3. Integração ao DataFrame Principal (Separando por objeto/banda)\n",
        "# Crie novos nomes de coluna para os valores de SNR, por exemplo, 'SNR_uJAVA', 'SNR_J0378'\n",
        "bandas_snr_names = [f'SNR_{name}' for name in filter_names]\n",
        "\n",
        "# Cria um novo DataFrame para SNR com nomes de coluna apropriados\n",
        "df_snr = pd.DataFrame(snr_calculated_values.values, columns=bandas_snr_names)\n",
        "\n",
        "# Adiciona os IDs originais (TILE_ID e NUMBER) e outros metadados relevantes de df_err_flux\n",
        "df_snr.insert(0, 'TILE_ID', df_err_flux['TILE_ID'].values)\n",
        "df_snr.insert(1, 'NUMBER', df_err_flux['NUMBER'].values)\n",
        "df_snr['Plx'] = df_err_flux['Plx'].values\n",
        "df_snr['e_Plx'] = df_err_flux['e_Plx'].values\n",
        "df_snr['erro_relativo_paralaxe'] = df_err_flux['erro_relativo_paralaxe'].values\n",
        "\n",
        "# --- FIM DA IMPLEMENTAÇÃO DO SNR ---\n",
        "\n",
        "# 4. Cálculo de Estatísticas de Qualidade (Sugestão para seu dashboard)\n",
        "df_snr['SNR_MEDIO'] = df_snr[bandas_snr_names].mean(axis=1)\n",
        "df_snr['SNR_MAX'] = df_snr[bandas_snr_names].max(axis=1)\n",
        "\n",
        "# 5. Visualização de Controle (Dashboard Simples)\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_snr['SNR_MEDIO'], bins=50, kde=True, color='royalblue')\n",
        "plt.title('Distribuição do SNR Médio (57 bandas)')\n",
        "plt.xlabel('Signal-to-Noise Ratio')\n",
        "plt.ylabel('Frequência (Objetos)')\n",
        "plt.axvline(x=3, color='red', linestyle='--', label='SNR=3 (Limite de Detecção)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 6. Salvando o Processamento Final\n",
        "output_file = os.path.join(path_dir, 'DF_PROCESSADO_COM_SNR.csv')\n",
        "df_snr.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Processamento concluído com sucesso!\")\n",
        "print(f\"O DataFrame de SNR agora contém {df_snr.shape[1]} colunas (IDs + 57 bandas + estatísticas).\")"
      ],
      "metadata": {
        "id": "a8sg2zvnsEu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.4 Histograma do sinal/ruído de cada banda**\n",
        "\n",
        "FASE 3: Visualização dos Dados, tenta a primeira abordagem de visualização: plotar os histogramas de SNR para todas as 57 bandas (excluindo iSDSS ) em um grande painel de subplots.\n",
        "\n",
        "Interatividade: O código lista todas as bandas disponíveis e solicita ativamente que o usuário digite os números das bandas que deseja analisar (ex: \"45,7,39\").\n",
        "Robustez: Utiliza threading para criar um timeout de 2 minutos. Se o usuário não responder, o script não trava; ele seleciona 3 bandas aleatoriamente e continua.\n",
        "Análise Focada: Ele então plota histogramas limpos apenas para as bandas selecionadas, incluindo linhas de média e mediana.\n",
        "Relatório Detalhado: Por fim, imprime estatísticas descritivas (mínimo, máximo, média, mediana, desvio padrão) apenas para as bandas selecionadas.\n",
        "Esta abordagem interativa é uma grande vantagem para a análise exploratória, permitindo ao cientista focar em bandas de interesse específico (ex: J0810, J0430, J0750)"
      ],
      "metadata": {
        "id": "WJ3VqnEV0X7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Preparação dos Dados (SNR já calculado anteriormente) ---\n",
        "# Caso df_snr não esteja na memória, ele deve ser gerado a partir do df_err_flux\n",
        "bandas_cols = [col for col in df_snr.columns if col.startswith('SNR_')]\n",
        "total_bandas = len(bandas_cols)\n",
        "\n",
        "# --- 2. Função de Captura de Input com Timeout ---\n",
        "def get_user_input_with_timeout(prompt, timeout_seconds=120):\n",
        "    \"\"\"\n",
        "    Captura input do usuário com timeout.\n",
        "    Retorna None se o tempo esgotar.\n",
        "    \"\"\"\n",
        "    from threading import Thread\n",
        "    import queue\n",
        "\n",
        "    def input_thread(q):\n",
        "        try:\n",
        "            q.put(input())\n",
        "        except:\n",
        "            q.put(None)\n",
        "\n",
        "    print(prompt, end='', flush=True)\n",
        "\n",
        "    q = queue.Queue()\n",
        "    thread = Thread(target=input_thread, args=(q,))\n",
        "    thread.daemon = True\n",
        "    thread.start()\n",
        "\n",
        "    # Aguarda pelo tempo especificado\n",
        "    thread.join(timeout=timeout_seconds)\n",
        "\n",
        "    if thread.is_alive():\n",
        "        print(f\"\\n[TIMEOUT] Tempo de {timeout_seconds//60} minutos excedido.\")\n",
        "        print(\"Selecionando 2 bandas aleatórias...\")\n",
        "        return None\n",
        "    else:\n",
        "        try:\n",
        "            return q.get_nowait()\n",
        "        except queue.Empty:\n",
        "            return None\n",
        "\n",
        "# --- 3. Interface de Interatividade ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPLORADOR DE BANDAS J-PAS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total de bandas disponíveis: {total_bandas}\")\n",
        "\n",
        "# Gerar opções de múltiplos de 3 até o limite\n",
        "multiplos_de_3 = []\n",
        "for i in range(3, total_bandas + 1, 3):\n",
        "    if i <= total_bandas:\n",
        "        multiplos_de_3.append(i)\n",
        "\n",
        "# Se não houver múltiplos exatos, adiciona o total como opção\n",
        "if total_bandas not in multiplos_de_3:\n",
        "    multiplos_de_3.append(total_bandas)\n",
        "\n",
        "# REMOVER ESPECIFICAMENTE O r59 se estiver na lista\n",
        "if 59 in multiplos_de_3:\n",
        "    multiplos_de_3.remove(59)\n",
        "\n",
        "prompt_text = (\n",
        "    \"\\nComo deseja proceder?\\n\"\n",
        "    \"- Digite os números das bandas (ex: 7, 39, 45)\\n\"\n",
        "    \"- Digite 'todas' para ver o painel completo\\n\"\n",
        "    \"- Para N bandas aleatórias, use o prefixo 'r' (ex: 'r6' para 6 bandas aleatórias)\\n\"\n",
        "    f\"\\nOpções de aleatorização disponíveis (múltiplos de 3):\\n\"\n",
        ")\n",
        "\n",
        "# Adiciona as opções formatadas em linhas\n",
        "opcoes_formatadas = []\n",
        "for i, n in enumerate(multiplos_de_3):\n",
        "    opcoes_formatadas.append(f\"r{n}\")\n",
        "    if (i + 1) % 5 == 0 or i == len(multiplos_de_3) - 1:\n",
        "        prompt_text += \"  \" + \", \".join(opcoes_formatadas[i-(i%5):i+1]) + \"\\n\"\n",
        "        opcoes_formatadas = opcoes_formatadas[:i+1]\n",
        "\n",
        "prompt_text += f\"\\nTempo disponível: 2 minutos\\n\"\n",
        "prompt_text += \"Sua escolha: \"\n",
        "\n",
        "# Chamada da função com timeout de 2 minutos (120 segundos)\n",
        "escolha = get_user_input_with_timeout(prompt_text, timeout_seconds=120)\n",
        "\n",
        "# --- 4. Lógica de Seleção ---\n",
        "# Timeout: seleciona 2 bandas aleatórias\n",
        "if escolha is None:\n",
        "    print(\"\\n[INFO] Nenhuma resposta recebida no tempo limite.\")\n",
        "    print(\"[AÇÃO] Selecionando 2 bandas aleatórias automaticamente...\")\n",
        "    if total_bandas >= 2:\n",
        "        selecionadas = random.sample(bandas_cols, 2)\n",
        "    else:\n",
        "        selecionadas = bandas_cols\n",
        "        print(f\"[AVISO] Apenas {total_bandas} banda(s) disponível(eis).\")\n",
        "\n",
        "elif escolha.lower() == 'todas':\n",
        "    selecionadas = bandas_cols\n",
        "    print(f\"\\n[INFO] Selecionadas todas as {len(selecionadas)} bandas.\")\n",
        "\n",
        "elif escolha.lower().startswith('r'):\n",
        "    # Seleção por número específico de bandas aleatórias (prefixo 'r')\n",
        "    try:\n",
        "        n_str = escolha.lower().replace('r', '').strip()\n",
        "        if n_str.isdigit():\n",
        "            n = int(n_str)\n",
        "\n",
        "            # Verificar se é múltiplo de 3 ou se é o total\n",
        "            multiplos_validos = multiplos_de_3.copy()\n",
        "            if total_bandas not in multiplos_validos:\n",
        "                multiplos_validos.append(total_bandas)\n",
        "\n",
        "            # ESPECIAL: se o usuário digitar r59, tratamos como entrada inválida\n",
        "            if n == 59:\n",
        "                print(f\"\\n[AVISO] Opção 'r59' não está disponível.\")\n",
        "                print(f\"[AÇÃO] Selecionando 3 bandas aleatórias.\")\n",
        "                n_default = min(3, total_bandas)\n",
        "                selecionadas = random.sample(bandas_cols, n_default)\n",
        "            elif n in multiplos_validos:\n",
        "                if n <= total_bandas:\n",
        "                    selecionadas = random.sample(bandas_cols, n)\n",
        "                    print(f\"\\n[INFO] Selecionadas {n} banda(s) aleatória(s).\")\n",
        "                else:\n",
        "                    print(f\"\\n[AVISO] Número {n} maior que bandas disponíveis ({total_bandas}).\")\n",
        "                    print(f\"[AÇÃO] Selecionando todas as {total_bandas} bandas.\")\n",
        "                    selecionadas = bandas_cols\n",
        "            else:\n",
        "                # Encontrar o múltiplo de 3 mais próximo\n",
        "                multiplo_mais_proximo = min(multiplos_validos, key=lambda x: abs(x - n))\n",
        "                print(f\"\\n[AVISO] Número {n} não é um múltiplo de 3 válido.\")\n",
        "                print(f\"[AÇÃO] Usando {multiplo_mais_proximo} bandas aleatórias.\")\n",
        "                selecionadas = random.sample(bandas_cols, multiplo_mais_proximo)\n",
        "        else:\n",
        "            print(f\"\\n[AVISO] Formato inválido: '{escolha}'. Use 'r' seguido do número.\")\n",
        "            print(f\"[AÇÃO] Selecionando 3 bandas aleatórias.\")\n",
        "            n_default = min(3, total_bandas)\n",
        "            selecionadas = random.sample(bandas_cols, n_default)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[ERRO] Processando '{escolha}': {e}\")\n",
        "        print(f\"[AÇÃO] Selecionando 3 bandas aleatórias.\")\n",
        "        n_default = min(3, total_bandas)\n",
        "        selecionadas = random.sample(bandas_cols, n_default)\n",
        "\n",
        "else:\n",
        "    # Verifica se é uma lista de números de bandas específicas\n",
        "    indices = []\n",
        "    partes_validas = []\n",
        "\n",
        "    for part in escolha.replace(',', ' ').split():\n",
        "        part = part.strip()\n",
        "        if part.isdigit():\n",
        "            idx = int(part) - 1\n",
        "            if 0 <= idx < total_bandas:\n",
        "                indices.append(bandas_cols[idx])\n",
        "                partes_validas.append(part)\n",
        "\n",
        "    if indices:\n",
        "        selecionadas = indices\n",
        "        print(f\"\\n[INFO] Selecionadas {len(selecionadas)} banda(s) específica(s): {', '.join(partes_validas)}\")\n",
        "    else:\n",
        "        # Entrada inválida - seleciona 3 bandas aleatórias por padrão\n",
        "        print(f\"\\n[AVISO] Entrada não reconhecida: '{escolha}'\")\n",
        "        print(\"[AÇÃO] Selecionando 3 bandas aleatórias...\")\n",
        "        n_default = min(3, total_bandas)\n",
        "        selecionadas = random.sample(bandas_cols, n_default)\n",
        "\n",
        "# --- 5. Plotagem e Relatório Detalhado ---\n",
        "if selecionadas:\n",
        "    print(f\"\\n[PROCESSANDO] Gerando análise para {len(selecionadas)} banda(s)...\")\n",
        "\n",
        "    # Configuração de subplots\n",
        "    n_sel = len(selecionadas)\n",
        "    n_cols = min(3, n_sel)\n",
        "    n_rows = (n_sel + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows), squeeze=False)\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    stats_list = []\n",
        "\n",
        "    for i, col in enumerate(selecionadas):\n",
        "        ax = axes_flat[i]\n",
        "        dados = df_snr[col][df_snr[col] > 0].dropna()\n",
        "\n",
        "        if dados.empty:\n",
        "            print(f\"[AVISO] Banda {col.replace('SNR_', '')}: Sem dados válidos.\")\n",
        "            ax.text(0.5, 0.5, 'Sem dados', transform=ax.transAxes,\n",
        "                    ha='center', va='center', fontsize=12)\n",
        "            continue\n",
        "\n",
        "        # Estatísticas\n",
        "        desc = dados.describe()\n",
        "        stats_list.append(desc)\n",
        "\n",
        "        # Plot\n",
        "        limite = np.percentile(dados, 98) if not dados.empty else 100\n",
        "        sns.histplot(dados, bins=40, ax=ax, color='skyblue', kde=True, binrange=(0, limite))\n",
        "\n",
        "        # Linhas de Média e Mediana\n",
        "        mean_v = desc['mean']\n",
        "        median_v = desc['50%']\n",
        "        ax.axvline(mean_v, color='darkblue', linestyle='-', label=f'Média: {mean_v:.2f}')\n",
        "        ax.axvline(median_v, color='green', linestyle='--', label=f'Mediana: {median_v:.2f}')\n",
        "        ax.axvline(3, color='red', linestyle=':', alpha=0.5, label='SNR=3')\n",
        "\n",
        "        # Título\n",
        "        band_display_name = col.replace('SNR_', '')\n",
        "        ax.set_title(f'Banda {band_display_name}', fontsize=14)\n",
        "        ax.legend()\n",
        "\n",
        "    # Remover eixos extras\n",
        "    for j in range(i + 1, len(axes_flat)):\n",
        "        fig.delaxes(axes_flat[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- 6. Relatório Detalhado ---\n",
        "    if stats_list:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RELATÓRIO ESTATÍSTICO DAS BANDAS SELECIONADAS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Criar DataFrame de estatísticas\n",
        "        df_stats = pd.DataFrame()\n",
        "        for i, (col, desc) in enumerate(zip(selecionadas, stats_list)):\n",
        "            band_name = col.replace('SNR_', '')\n",
        "            df_stats[f'Banda_{band_name}'] = desc\n",
        "\n",
        "        # Adicionar desvio padrão se não estiver presente\n",
        "        if 'std' not in df_stats.index:\n",
        "            for col in selecionadas:\n",
        "                band_name = col.replace('SNR_', '')\n",
        "                df_stats.loc['std', f'Banda_{band_name}'] = df_snr[col].std()\n",
        "\n",
        "        # Mostrar estatísticas principais\n",
        "        indices_show = ['count', 'min', 'max', 'mean', '50%', 'std']\n",
        "        indices_show = [idx for idx in indices_show if idx in df_stats.index]\n",
        "\n",
        "        print(df_stats.loc[indices_show].rename(index={'50%': 'median'}))\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Resumo estatístico adicional\n",
        "        print(\"\\nRESUMO:\")\n",
        "        for i, (col, desc) in enumerate(zip(selecionadas, stats_list)):\n",
        "            band_name = col.replace('SNR_', '')\n",
        "            print(f\"Banda {band_name}:\")\n",
        "            print(f\"  - Objetos com SNR>0: {int(desc['count']):,}\")\n",
        "            print(f\"  - SNR médio: {desc['mean']:.2f}\")\n",
        "            print(f\"  - SNR mediano: {desc['50%']:.2f}\")\n",
        "            print(f\"  - Faixa: [{desc['min']:.2f}, {desc['max']:.2f}]\")\n",
        "\n",
        "            # Porcentagem com SNR > 3\n",
        "            perc_snr3 = (df_snr[col] > 3).sum() / desc['count'] * 100 if desc['count'] > 0 else 0\n",
        "            print(f\"  - Objetos com SNR>3: {perc_snr3:.1f}%\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n[ERRO] Nenhuma banda foi selecionada ou disponível.\")"
      ],
      "metadata": {
        "id": "XCbE4CCqjhkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM TESTE"
      ],
      "metadata": {
        "id": "wj5nvNcH0N-G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yV46BBzK0gb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SALVANDO TODOS OS RESULTADOS**"
      ],
      "metadata": {
        "id": "LMytW2va2EAK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_kox2EZU2GSb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}